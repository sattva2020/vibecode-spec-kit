# ü§ñ Ollama Models Configuration

## üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### **–û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ (RAG System)**

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –°—Ç–∞—Ç—É—Å |
|--------|--------|------------|--------|
| **qwen2.5-coder:1.5b** | 1.5B | –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ | ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞—è |
| **qwen2.5-coder:7b** | 7B | –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è | ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞—è |
| **nomic-embed-text** | 274M | –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è RAG | ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞—è |

### **Intelligent n8n System –º–æ–¥–µ–ª–∏**

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è |
|--------|--------|------------|--------------|
| **llama3.2:3b** | 3B | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ | `OLLAMA_MODEL_CODE` |
| **llama3.2:7b** | 7B | –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–æ–≤ | `OLLAMA_MODEL_ANALYSIS` |
| **nomic-embed-text:latest** | 274M | –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ | `OLLAMA_MODEL_EMBEDDING` |

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
# –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ (Windows)
.\scripts\start-rag-system.ps1

# –ò–ª–∏ –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ Docker
docker exec rag-ollama ollama pull qwen2.5-coder:1.5b
docker exec rag-ollama ollama pull qwen2.5-coder:7b
docker exec rag-ollama ollama pull nomic-embed-text
```

### –†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—É
docker exec -it rag-ollama bash

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π
ollama pull qwen2.5-coder:1.5b
ollama pull qwen2.5-coder:7b
ollama pull nomic-embed-text
ollama pull llama3.2:3b
ollama pull llama3.2:7b
```

## üìä –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–µ–π

### **qwen2.5-coder:1.5b**
- **–†–∞–∑–º–µ—Ä**: 1.5B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ü–∞–º—è—Ç—å**: ~1GB RAM
- **–°–∫–æ—Ä–æ—Å—Ç—å**: –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è (1-2 —Å–µ–∫)
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –•–æ—Ä–æ—à–µ–µ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–æ–¥–∞
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: Inline completions, –±—ã—Å—Ç—Ä—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

### **qwen2.5-coder:7b**
- **–†–∞–∑–º–µ—Ä**: 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ü–∞–º—è—Ç—å**: ~4GB RAM
- **–°–∫–æ—Ä–æ—Å—Ç—å**: –ë—ã—Å—Ç—Ä–∞—è (2-4 —Å–µ–∫)
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –û—Ç–ª–∏—á–Ω–æ–µ –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –∫–æ–¥–∞
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: –û—Å–Ω–æ–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥

### **llama3.2:3b**
- **–†–∞–∑–º–µ—Ä**: 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ü–∞–º—è—Ç—å**: ~2GB RAM
- **–°–∫–æ—Ä–æ—Å—Ç—å**: –ë—ã—Å—Ç—Ä–∞—è (2-3 —Å–µ–∫)
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –•–æ—Ä–æ—à–µ–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ n8n system

### **llama3.2:7b**
- **–†–∞–∑–º–µ—Ä**: 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ü–∞–º—è—Ç—å**: ~4GB RAM
- **–°–∫–æ—Ä–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è (3-5 —Å–µ–∫)
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –û—Ç–ª–∏—á–Ω–æ–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–æ–≤

### **nomic-embed-text**
- **–†–∞–∑–º–µ—Ä**: 274M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ü–∞–º—è—Ç—å**: ~500MB RAM
- **–°–∫–æ—Ä–æ—Å—Ç—å**: –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è (<1 —Å–µ–∫)
- **–ö–∞—á–µ—Å—Ç–≤–æ**: –í—ã—Å–æ–∫–æ–µ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: RAG –ø–æ–∏—Å–∫, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –û—Å–Ω–æ–≤–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞
OLLAMA_MODEL=qwen2.5-coder:7b

# Intelligent n8n System
OLLAMA_MODEL_CODE=llama3.2:3b
OLLAMA_MODEL_EMBEDDING=nomic-embed-text:latest
OLLAMA_MODEL_ANALYSIS=llama3.2:7b
OLLAMA_BASE_URL=http://localhost:11434
```

### –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ –∑–∞–¥–∞—á–µ

```python
def select_model(task_type: str) -> str:
    """–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
    if task_type == "quick_completion":
        return "qwen2.5-coder:1.5b"  # –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    elif task_type == "code_generation":
        return "qwen2.5-coder:7b"    # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    elif task_type == "analysis":
        return "llama3.2:7b"         # –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
    elif task_type == "embedding":
        return "nomic-embed-text"    # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
    else:
        return "qwen2.5-coder:7b"    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
```

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π

### –°–ø–∏—Å–æ–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
```bash
# –ß–µ—Ä–µ–∑ API
curl http://localhost:11434/api/tags

# –ß–µ—Ä–µ–∑ Docker
docker exec rag-ollama ollama list
```

### –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
```bash
# –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
curl http://localhost:11434/api/generate \
  -d '{
    "model": "qwen2.5-coder:7b",
    "prompt": "Write a Python function to calculate factorial:",
    "stream": false
  }'
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
```bash
# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
docker stats rag-ollama

# –õ–æ–≥–∏ Ollama
docker logs rag-ollama -f
```

### –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- **–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞**: <500ms –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏**: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —á–µ—Ä–µ–∑ Grafana
- **–ó–∞–≥—Ä—É–∑–∫–∞ GPU**: –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
1. **qwen2.5-coder:1.5b** - –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö inline completions
2. **qwen2.5-coder:7b** - –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
3. **nomic-embed-text** - –¥–ª—è RAG –ø–æ–∏—Å–∫–∞

### –î–ª—è production
1. **llama3.2:7b** - –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
2. **qwen2.5-coder:7b** - –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
3. **nomic-embed-text** - –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è real-time —Ñ—É–Ω–∫—Ü–∏–π
- –ö–µ—à–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤
- –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ GPU
